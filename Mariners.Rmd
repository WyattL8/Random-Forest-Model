---
title: "Wyatt Lefkowitz - Mariners Analytics Internship - Problem 1 Code"
output: html_document
date: "2024-10-26"
---

```{r}
# Load necessary libraries
library(readr) # for loading in csv
library(dplyr) # many data manipulation functions
library(caret) # model eval using cross-validation
library(tidyr) # more data help
library(tidyverse) # more data help
library(randomForest) # the model we are going to use
```


```{r}
# Loading the data in
data_dict <- read.csv("/Users/owner/desktop/data-dictionary.csv")
train_data <- read.csv("/Users/owner/desktop/data-train.csv")
test_data <- read.csv("/Users/owner/desktop/data-test.csv")
```

```{r}
# DATA PREP

# R does not like 1's and 0's, so converting those to explanatory strings

train_data <- train_data %>%
  mutate(is_airout = if_else(is_airout == 1, "caught", "not_caught"))

# Also converting A and B levels to high and low just to be safe
train_data <- train_data %>%
  mutate(level = if_else(level == 'A', "high", "low"))

test_data <- test_data %>%
  mutate(level = if_else(level == 'A', "high", "low"))

# Add a new column 'same_side' that is 2 if bat_side and pitch_side are the
# same, 1 otherwise. This is an attempt to capture if having the platoon 
# advantage or not impacts outfielder jumps/reads on the baseball
train_data <- train_data %>%
  mutate(same_side = if_else(bat_side == pitch_side, 2, 1))

# Do the same for test_data
test_data <- test_data %>%
  mutate(same_side = if_else(bat_side == pitch_side, 2, 1))

# Removing features that I deem not necessary for the model
train_data <- train_data %>%
  select(-pitch_id, -gamedate, -bat_side, -pitch_side, -inning, -top, 
         -pre_balls, -pre_strikes, -pre_outs, -lf_id, -cf_id, -rf_id)

test_data <- test_data %>%
  select(-pitch_id, -gamedate, -bat_side, -pitch_side, -inning, -top, 
         -pre_balls, -pre_strikes, -pre_outs)

# Convert categorical variables and ID's in the sets into factors so they can 
# be used properly for analysis
train_data$temperature <- as.numeric(train_data$temperature)
train_data$same_side <- as.factor(train_data$same_side)
train_data$level <- as.factor(train_data$level)
train_data$is_airout <- as.factor(train_data$is_airout)
train_data$venue_id <- as.factor(train_data$venue_id)

test_data$same_side <- as.factor(test_data$same_side)
test_data$level <- as.factor(test_data$level)
test_data$venue_id <- as.factor(test_data$venue_id)

# Combine all unseen levels in the test data into "Other" as there are venues
# in the test set which are not seen in the train set. This can throw off the
# random forest model
combined_levels <- levels(train_data$venue_id)
test_data$venue_id <- fct_other(test_data$venue_id, keep = combined_levels)
```


```{r}
# This is for handling null entries

# For integer columns, use the median and convert to integer
train_data <- train_data %>%
  mutate(across(where(is.integer), ~replace_na(., as.integer(median(., na.rm = TRUE)))))

test_data <- test_data %>%
  mutate(across(where(is.integer), ~replace_na(., as.integer(median(., na.rm = TRUE)))))

# For numeric columns, use the mean without rounding
train_data <- train_data %>%
  mutate(across(where(is.double), ~replace_na(., mean(., na.rm = TRUE))))

test_data <- test_data %>%
  mutate(across(where(is.double), ~replace_na(., mean(., na.rm = TRUE))))

```


```{r}
# Take out first_fielder since it only applies when ball is caught, so it gives 
# away the answer to the model
X_train <- train_data %>% select(-first_fielder) 

# outcome variable, what we're trying to predict in the test set
X_train$y_train <- X_train$is_airout
```

```{r}
# Set up repeated cross validation for increased accuracy
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3, 
                        classProbs = TRUE)

# Make our X_test data frame
X_test <- test_data 
```

```{r}
# This is for memory storage purposes
rm(train_data, data_dict)
gc()

# Finally, we remove is_airout since we don't want any data leakage issues
X_train <- X_train %>% select(-is_airout)

# Random forest model trainer with cross validation
rf_model_cv <- train(as.factor(y_train) ~ ., data = X_train, method = "rf", 
  trControl = control,ntree = 100)
```

```{r}
# Check results
print(rf_model_cv)
```

```{r}
# Run the prediction model to get our probabilities
test_pred_rf_cv <- predict(rf_model_cv, X_test, type="prob")[, 2] 
```

```{r}
# Fill predictions into test data and save
test_data$p_airout <- test_pred_rf_cv
```


```{r}
# Export our predictions into csv file
write_csv(test_data, "/Users/owner/desktop/output-data-test.csv")
```

```{r}
# This is for generating insights into which variables impacted the model the 
# most. It turns out that horizontal exit angle is the strongest predictor.
importance_values <- varImp(rf_model_cv)
print(importance_values)
plot(importance_values)
```

```{r}
# Please feel free to reach out if you have any questions about my code!
# My accuracy on the cross-validation sets was roughly 90%, so I'm hoping to get
# a competitive log loss score on the test data.
```


